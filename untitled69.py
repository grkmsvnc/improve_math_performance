# -*- coding: utf-8 -*-
"""Untitled69.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c2C2sn6gsM-9HwPAiTHPenh8Q2FLiFMS
"""

import torch
import json
import pandas as pd
import random
import subprocess  # To run external programs and commands
import time
from collections import Counter
import signal  # For handling timeouts and signals
import tempfile  # To create temporary files and directories
import os
import re  # Regular expressions for string manipulation
from contextlib import contextmanager  # To create context managers
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline  # Hugging Face transformers
from huggingface_hub import login  # For logging into the Hugging Face hub

# Check if GPU is available and prompt the user to switch if not
if not torch.cuda.is_available():
    print("Please set the runtime to GPU: Runtime > Change runtime type > GPU")
# Install necessary libraries
!pip install transformers datasets torch accelerate bitsandbytes pandas sympy numpy

# Login to Hugging Face using a provided token
huggingface_token = "HF_TOKEN"
login(huggingface_token)

# Load the Mistral-7B-Instruct model with 4-bit quantization to optimize performance and reduce memory usage
model_name = "mistralai/Mistral-7B-Instruct-v0.1"
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_use_double_quant=True,
)
# Load the model and tokenizer
model_4bit = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto", quantization_config=quantization_config)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Create a text-generation pipeline with the model and tokenizer
pipeline_inst = pipeline(
    "text-generation",
    model=model_4bit,
    tokenizer=tokenizer,
    use_cache=True,
    device_map="auto",
    max_length=1000,
    do_sample=True,
    top_k=5,
    num_return_sequences=1,
    eos_token_id=tokenizer.eos_token_id,
    pad_token_id=tokenizer.eos_token_id,
)

# Function to load JSONL files and convert them to a pandas DataFrame
def load_jsonl(file_path):
    data = []
    with open(file_path, 'r') as f:
        for line in f:
            data.append(json.loads(line))
    return pd.DataFrame(data)

# Clone the dataset repository from GitHub and load the specific datasets into pandas DataFrames
!git clone https://github.com/openai/prm800k.git
train_data = load_jsonl('/content/prm800k/prm800k/math_splits/train.jsonl')
test_data = load_jsonl('/content/prm800k/prm800k/math_splits/test.jsonl')
mmlu_physics = pd.read_csv('/content/high_school_physics_test.csv')
mmlu_biology = pd.read_csv('/content/high_school_biology_test.csv')
mmlu_chemistry = pd.read_csv('/content/high_school_chemistry_test.csv')

# Print the column names of each dataset to verify successful loading
print(train_data.columns)
print(test_data.columns)
print(mmlu_physics.columns)
print(mmlu_biology.columns)
print(mmlu_chemistry.columns)

# Class to manage a Python REPL (Read-Eval-Print Loop) with a timeout to prevent infinite execution
class PythonREPL:
    def __init__(self, timeout=5):
        self.timeout = timeout

    # Context manager to set a time limit for code execution
    @contextmanager
    def time_limit(self, seconds):
        def signal_handler(*_):
            raise TimeoutError(f"Timed out after {seconds} seconds.")
        signal.signal(signal.SIGALRM, signal_handler)
        signal.alarm(seconds)
        try:
            yield
        finally:
            signal.alarm(0)

    # Method to execute a given Python code string with a timeout
    def __call__(self, query):
        # Prepend common imports to the query
        query = "import math\nimport numpy as np\nimport sympy as sp\n" + query
        query = query.strip().split("\n")
        # Ensure the last line is a print statement for output
        if "print(" not in query[-1]:
            if "#" in query[-1]:
                query[-1] = query[-1].split("#")[0]
            query[-1] = "print(" + query[-1] + ")"
        query = "\n".join(query)
        # Create a temporary file to save the query
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_file_path = os.path.join(temp_dir, "tmp.py")
            with open(temp_file_path, "w", encoding="utf-8") as f:
                f.write(query)
            # Run the code with a time limit
            with self.time_limit(self.timeout):
                result = subprocess.run(
                    ["python3", temp_file_path],
                    capture_output=True,
                    check=False,
                    text=True,
                    timeout=self.timeout,
                )
                if result.returncode == 0:
                    output = result.stdout
                    return True, output.strip()
                # Handle errors and format error messages
                error_msg = result.stderr.strip()
                msgs = error_msg.split("\n")
                new_msgs = []
                want_next = False
                for m in msgs:
                    if "Traceback" in m:
                        new_msgs.append(m)
                    elif m == msgs[-1]:
                        new_msgs.append(m)
                    elif temp_file_path in m:
                        st = m.index('"/') + 1 if '"/' in m else 0
                        ed = m.index(temp_file_path) + 1 if temp_file_path in m else None
                        clr = m[st:ed] if not ed else m[st:]
                        m = m.replace(clr, "")
                        new_msgs.append(m)
                        want_next = True
                    elif want_next:
                        new_msgs.append(m)
                        want_next = False
                error_msg = "\n".join(new_msgs)
                return False, error_msg.strip()

# Function to execute code completions, managing multiple code blocks in a single completion
def execute_completion(executor, completion, return_status, last_code_block):
    # Find all code blocks in the completion
    executions = re.findall(r"```python(.*?)```", completion, re.DOTALL)
    if len(executions) == 0:
        return completion, False if return_status else completion
    if last_code_block:
        executions = [executions[-1]]
    outputs = []
    successes = []
    for code in executions:
        success = False
        # Check for disallowed libraries
        for lib in ("subprocess", "venv"):
            if lib in code:
                output = f"{lib} is not allowed"
                outputs.append(output)
                successes.append(success)
                continue
        try:
            # Execute the code block
            success, output = executor(code)
        except TimeoutError as e:
            print("Code timed out")
            output = e
        if not success and not return_status:
            output = ""
        outputs.append(output)
        successes.append(success)
    output = str(outputs[-1]).strip()
    success = successes[-1]
    if return_status:
        return output, success
    return output

# Function to handle post-processing of completion results, including execution of any code blocks
def postprocess_completion(text, return_status, last_code_block):
    executor = PythonREPL()
    result = execute_completion(executor, text, return_status=return_status, last_code_block=last_code_block)
    del executor
    return result

# Function to extract boxed answers from LaTeX formatted text
def extract_boxed_answer(text):
    def last_boxed_only_string(text):
        idx = text.rfind("\\boxed")
        if idx < 0:
            idx = text.rfind("\\fbox")
            if idx < 0:
                return None
        i = idx
        right_brace_idx = None
        num_left_braces_open = 0
        while i < len(text):
            if text[i] == "{":
                num_left_braces_open += 1
            if text[i] == "}":
                num_left_braces_open -= 1
                if num_left_braces_open == 0:
                    right_brace_idx = i
                    break
            i += 1
        if right_brace_idx is None:
            return None
        return text[idx : right_brace_idx + 1]

    def remove_boxed(boxed):
        left = "\\boxed{"
        try:
            assert boxed[: len(left)] == left
            assert boxed[-1] == "}"
            length = len(left)
            return boxed[length:-1]
        except Exception:
            return None

    boxed = last_boxed_only_string(text)
    if boxed is None:
        return None
    answer = remove_boxed(boxed)
    return answer if answer else "No valid boxed answer found"

# Function to normalize answers by removing formatting and standardizing the text
def normalize_answer(answer):
    match = re.search(r"(.*?)Problem:", answer, flags=re.S)
    if match:
        answer = match.group(1)
    subs = [("an ", ""), ("a ", ""), (".$", "$"), ("\\$", ""), (r"\ ", ""), (" ", ""), ("mbox", "text"), (",\\text{and}", ","), ("\\text{and}", ","), ("\\text{m}", "\\text{}"), ("\\le", "<")]
    remove = ["square", "ways", "integers", "dollars", "mph", "inches", "ft", "hours", "km", "units", "\\ldots", "sue", "points", "feet", "minutes", "digits", "cents", "degrees", "cm", "gm", "pounds", "meters", "meals", "edges", "students", "childrentickets", "multiples", "\\text{s}", "\\text{.}", "\\text{\ns}", "\\text{}^2", "\\text{}^3", "\\text{\n}", "\\text{}", r"\mathrm{th}", r"^\circ", r"^{\circ}", r"\;", r",\!", "{,}", '"', "\\dots", "\n", "\r", "\f", "\%"]
    sub_patterns = [r"(\\text\{)(.*?)(\})", r"(\\textbf\{)(.*?)(\})", r"(\\overline\{)(.*?)(\})", r"(\\boxed\{)(.*)(\})"]
    split_patterns = [r"finalansweris(.*)", r"answer?is:?(.*)", r"oxed\{(.*?)\}", r"\$(.*?)\$"]
    for before, after in subs:
        answer = answer.replace(before, after)
    for expr in remove:
        answer = answer.replace(expr, "")
    for pattern in sub_patterns:
        answer = re.sub(pattern, "\\2", answer)
    for pattern in split_patterns:
        if len(re.findall(pattern, answer)) > 0:
            answer = re.findall(pattern, answer)[-1]
    answer = answer.strip()
    if "rac" in answer and "\\frac" not in answer:
        answer = answer.replace("rac", "\\frac")
    answer = re.sub(r"(frac)([^{])(.)", "frac{\\2}{\\3}", answer)
    answer = re.sub(r"(sqrt)([^{])", "sqrt{\\2}", answer)
    answer = answer.replace("$", "")
    if answer.replace(",", "").isdigit():
        answer = answer.replace(",", "")
    return answer

# Generate multiple reasoning paths to approach the problem
def generate_reasoning_paths(question, num_paths):
    reasoning_paths = []
    base_prompt = f"Q: {question}\nA: The problem requires us to"
    reasoning_choices = [
        " split the integers into pairs such that each pair meets the criteria. To solve this, we will:\n"
        "1. Generate all possible pairs of integers using Python's itertools library.\n"
        "2. Filter out pairs that do not meet the criteria.\n"
        "3. Count the number of valid pairs.",
        " find all valid pairings using a combinatorial approach. We'll use Python to enumerate all pairs and filter them:\n"
        "1. Import the itertools library to generate combinations.\n"
        "2. Create a function to check if a pair meets the criteria.\n"
        "3. Iterate over all possible pairs and filter out the valid ones.\n"
        "4. Return the count of valid pairs.",
        " solve the problem by generating all possible pairings and checking each one:\n"
        "1. Use a brute-force approach to generate all combinations.\n"
        "2. Define a function to validate each pair based on the given criteria.\n"
        "3. Apply the validation function to each combination.\n"
        "4. Keep a count of all valid pairs and return the result.",
        " use a recursive function to generate and validate pairs:\n"
        "1. Define a recursive function to generate pairs.\n"
        "2. In each recursion, check if the generated pair meets the criteria.\n"
        "3. If valid, add to the count of valid pairs.\n"
        "4. Return the final count after all recursions are complete.",
        " employ dynamic programming to solve the problem efficiently:\n"
        "1. Define a dynamic programming table to store intermediate results.\n"
        "2. Fill the table based on the pairing criteria.\n"
        "3. Use the table to count the number of valid pairs without redundant calculations.\n"
        "4. Return the final count from the dynamic programming table.",
        " apply a mathematical approach to reduce the problem space:\n"
        "1. Analyze the mathematical properties of the criteria.\n"
        "2. Derive a formula or heuristic to directly count valid pairs.\n"
        "3. Implement the derived formula in Python.\n"
        "4. Return the result from the formula implementation.",
        " use a graph-based approach to model the problem:\n"
        "1. Represent integers as nodes in a graph.\n"
        "2. Define edges based on the pairing criteria.\n"
        "3. Use a graph traversal algorithm to find all valid pairings.\n"
        "4. Count and return the number of valid pairs found.",
        " leverage combinatorial algorithms to find solutions:\n"
        "1. Use combinatorial generation techniques to list all pairs.\n"
        "2. Implement a function to validate each pair based on the criteria.\n"
        "3. Iterate through the generated pairs and apply the validation function.\n"
        "4. Count and return the number of pairs that meet the criteria."
    ]
    for _ in range(num_paths):
        reasoning = random.choice(reasoning_choices)
        full_prompt = base_prompt + reasoning
        reasoning_paths.append(full_prompt)
    return reasoning_paths

# Execute generated code and capture the output
def execute_code(code):
    try:
        result = subprocess.run(['python', '-c', code], capture_output=True, text=True, timeout=CODE_TIMEOUT)
        return result.stdout.strip() if result.returncode == 0 else result.stderr.strip()
    except subprocess.TimeoutExpired:
        return "Execution timed out."

# Generate code based on reasoning paths and execute it
def generate_code_and_execute(pipeline_inst, question, num_paths, num_iterations):
    reasoning_paths = generate_reasoning_paths(question, num_paths)
    candidates = []
    for _ in range(num_iterations):
        for reasoning_path in reasoning_paths:
            start_time = time.time()
            generated_code = pipeline_inst(reasoning_path)[0]['generated_text'].split("Q:")[0].strip()
            execution_time = time.time() - start_time
            if execution_time > CODE_GENERATION_LIMIT:
                print(f"Code generation took too long: {execution_time:.2f} seconds")
                continue
            output = execute_code(generated_code)
            candidates.append(output)
    return candidates

# Elimination voting mechanism to find the best candidate answer
def elimination_voting(candidates):
    while len(candidates) > 1:
        counter = Counter(candidates)
        least_common = counter.most_common()[:-2:-1]
        least_common_candidate = least_common[0][0]
        candidates = [candidate for candidate in candidates if candidate != least_common_candidate]
    return candidates[0] if candidates else None

# Self-consistency tool integrated reasoning to answer questions
def self_consistency_tool_integrated_reasoning(pipeline_inst, question, num_paths=NUM_PATHS, num_iterations=NUM_ITERATIONS):
    reasoning_paths = generate_reasoning_paths(question, num_paths)
    candidates = []
    executor = PythonREPL(timeout=CODE_TIMEOUT)
    for _ in range(num_iterations):
        for reasoning_path in reasoning_paths:
            start_time = time.time()
            generated_code = pipeline_inst(reasoning_path)[0]['generated_text'].split("Q:")[0].strip()
            execution_time = time.time() - start_time
            if execution_time > CODE_GENERATION_LIMIT:
                print(f"Code generation took too long: {execution_time:.2f} seconds")
                continue
            success, output = executor(generated_code)
            if success:
                candidates.append(output)
            else:
                print(f"Code execution failed: {output}")
    final_answer = elimination_voting(candidates)
    return final_answer if final_answer else "No valid answer found"

# Evaluate the model's performance on a given dataset
def evaluate_model_sc_tir(dataset, question_col, answer_col, num_samples=10):
    correct_answers = 0
    total_samples = min(num_samples, len(dataset))
    for i in range(total_samples):
        question = dataset.iloc[i][question_col]
        correct_answer = dataset.iloc[i][answer_col]
        predicted_answer = self_consistency_tool_integrated_reasoning(pipeline_inst, question)
        if not predicted_answer:
            predicted_answer = "No valid answer found"
        predicted_answer = extract_boxed_answer(predicted_answer)
        if predicted_answer:
            predicted_answer = normalize_answer(predicted_answer)
        print(f"Question: {question}")
        print(f"Predicted Answer: {predicted_answer}")
        print(f"Correct Answer: {correct_answer}\n")
        if correct_answer == predicted_answer:
            correct_answers += 1
    accuracy = correct_answers / total_samples
    return accuracy

# Evaluate and print the model's accuracy on different datasets
test_accuracy_sc_tir = evaluate_model_sc_tir(test_data, "problem", "solution")
print(f"Test Dataset Accuracy with SC-TIR: {test_accuracy_sc_tir * 100:.2f}%")
mmlu_physics_accuracy_sc_tir = evaluate_model_sc_tir(mmlu_physics, mmlu_physics.columns[0], mmlu_physics.columns[5])
print(f"MMLU Physics Subtask Accuracy with SC-TIR: {mmlu_physics_accuracy_sc_tir * 100:.2f}%")
mmlu_biology_accuracy_sc_tir = evaluate_model_sc_tir(mmlu_biology, mmlu_biology.columns[0], mmlu_biology.columns[5])
print(f"MMLU Biology Subtask Accuracy with SC-TIR: {mmlu_biology_accuracy_sc_tir * 100:.2f}%")
mmlu_chemistry_accuracy_sc_tir = evaluate_model_sc_tir(mmlu_chemistry, mmlu_chemistry.columns[0], mmlu_chemistry.columns[5])
print(f"MMLU Chemistry Subtask Accuracy with SC-TIR: {mmlu_chemistry_accuracy_sc_tir * 100:.2f}%")

# Process code within generated samples and handle errors or missing code blocks
def process_code(sample, restart_on_fail, last_step, check_last_n_chars=100):
    gen_text = sample["gen_texts"]
    num_python_blocks = len(re.findall(r"```python(.*?)```", gen_text, re.DOTALL))
    region_to_check = gen_text[-check_last_n_chars:]
    if num_python_blocks == 0:
        if restart_on_fail:
            print("no code has ever been generated, RESTARTING")
            sample["gen_texts"] = sample["text"]
        else:
            print("no code has ever been generated, STOP")
            sample["should_prune"] = True
            sample["has_code"] = False
        return sample
    if not gen_text.endswith("```output\n") and ("answer is" in region_to_check or "\\boxed" in region_to_check):
        num_output_blocks = len(re.findall(r"```output(.*?)```", gen_text, re.DOTALL))
        if num_output_blocks == 0:
            print("The model hallucinated the code answer")
            sample["should_prune"] = True
            return sample
        if "boxed" in region_to_check:
            try:
                answer = normalize_answer(extract_boxed_answer(region_to_check))
            except Exception:
                answer = "-1"
        else:
            answer = normalize_answer(region_to_check)
        sample["model_answers"] = answer
        return sample
    if last_step:
        return sample
    if not gen_text.endswith("```output\n"):
        print("warning: output block not found: ", gen_text[-40:])
        if restart_on_fail:
            sample["gen_texts"] = sample["text"]
        else:
            sample["should_prune"] = True
        return sample
    code_result, _ = postprocess_completion(gen_text, return_status=True, last_code_block=True)
    truncation_limit = 200
    if len(code_result) > truncation_limit:
        code_result = code_result[:truncation_limit] + " ... (output truncated)"
    sample["gen_texts"] = gen_text + f"{code_result}\n```"
    return sample